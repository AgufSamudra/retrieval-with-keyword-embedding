{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "520f7934-f57c-4e08-8cd7-1572cbffec05",
   "metadata": {},
   "source": [
    "# Retrieval Data dengan Keywords Embedding\n",
    "\n",
    "Konsep dasar dari retrieval berbasis keyword adalah mengekstrak inti poin dari sebuah kalimat (keyword), kemudian melakukan retrieval menggunakan keyword tersebut. Pendekatan ini diharapkan dapat mengurangi `bias` dan membuat hasil retrieval menjadi lebih `fokus` serta `relevan`.\n",
    "\n",
    "## Cara melakukannya?\n",
    "\n",
    "1. **Cleaning data text** - lakukan preprocessing dasar (lowercase, hapus karakter khusus, dll.).\n",
    "2. **Stopword** (optional) - buang kata-kata umum yang tidak memiliki makna penting.\n",
    "3. **Tokenize sentence** - bisa menggunakan unigram atau n-gram sesuai kebutuhan.\n",
    "4. **Embedding** â€“ setiap token dan kalimat diubah menjadi embedding.\n",
    "5. **Similarity check** â€“ hitung cosine similarity antara setiap token dengan embedding kalimat.\n",
    "6. **Pilih top-N keyword** â€“ ambil token dengan skor tertinggi, ulangi untuk setiap kalimat.\n",
    "\n",
    "Hasil akhirnya, kita akan mendapatkan dokumen dengan top-N keywords yang paling representatif. Setelah keyword diperoleh, lakukan embedding kembali pada keyword tersebut dan simpan sebagai `keywords_embedding`.\n",
    "\n",
    "ðŸ“Œ Pada contoh ini saya menggunakan data QnA kesehatan dari Alodokter, tapi konsepnya bisa dengan mudah diterapkan pada berbagai jenis dokumen lain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1691bcf-1c14-4f5d-94d8-cf8a25cfe710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>doctor_name</th>\n",
       "      <th>tag</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bagaimana cara menghilangkan kurap dengan cepat?</td>\n",
       "      <td>dokter di lengan dan pundak kiri saya ada kura...</td>\n",
       "      <td>Alo, terimakasih atas pertanyaannya.\\n\\nRuam m...</td>\n",
       "      <td>dr. Nadia Nurotul Fuadah</td>\n",
       "      <td>infeksi-jamur kurap</td>\n",
       "      <td>https://www.alodokter.com/komunitas/topic/baga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pake obat apa untuk mengatasi jerawat hormonal?</td>\n",
       "      <td>hallo dokter, dok saat menjelang haid saya pas...</td>\n",
       "      <td>Alo, selamat siang\\nKemunculan jerawat saat ha...</td>\n",
       "      <td>dr. Riza Marlina</td>\n",
       "      <td>jerawat</td>\n",
       "      <td>https://www.alodokter.com/komunitas/topic/pake...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cara membersihkan telinga anak dirumah</td>\n",
       "      <td>alodokter, anak saya telinganya sering mengelu...</td>\n",
       "      <td>Alo, selamat siang\\nTelinga gatal bisa disebab...</td>\n",
       "      <td>dr. Riza Marlina</td>\n",
       "      <td>kebersihan kotoran-telinga</td>\n",
       "      <td>https://www.alodokter.com/komunitas/topic/cara...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Solusi mengatasi bayi usia 9 bulan susah makan</td>\n",
       "      <td>alodokter, saya mau bertanya, bayi saya usia 9...</td>\n",
       "      <td>Alo, selamat siang\\nBayi susah makan disebabka...</td>\n",
       "      <td>dr. Riza Marlina</td>\n",
       "      <td>nutrisi-bayi</td>\n",
       "      <td>https://www.alodokter.com/komunitas/topic/solu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Apa yang harus dilakukan ketika kaki kram saat...</td>\n",
       "      <td>permisi dok, dokter kalau mengatasi kaki suka ...</td>\n",
       "      <td>Alo, selamat siang\\nKaki kram dan seperti tert...</td>\n",
       "      <td>dr. Riza Marlina</td>\n",
       "      <td>kram</td>\n",
       "      <td>https://www.alodokter.com/komunitas/topic/apa-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Bagaimana cara menghilangkan kurap dengan cepat?   \n",
       "1    Pake obat apa untuk mengatasi jerawat hormonal?   \n",
       "2             Cara membersihkan telinga anak dirumah   \n",
       "3     Solusi mengatasi bayi usia 9 bulan susah makan   \n",
       "4  Apa yang harus dilakukan ketika kaki kram saat...   \n",
       "\n",
       "                                            question  \\\n",
       "0  dokter di lengan dan pundak kiri saya ada kura...   \n",
       "1  hallo dokter, dok saat menjelang haid saya pas...   \n",
       "2  alodokter, anak saya telinganya sering mengelu...   \n",
       "3  alodokter, saya mau bertanya, bayi saya usia 9...   \n",
       "4  permisi dok, dokter kalau mengatasi kaki suka ...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  Alo, terimakasih atas pertanyaannya.\\n\\nRuam m...   \n",
       "1  Alo, selamat siang\\nKemunculan jerawat saat ha...   \n",
       "2  Alo, selamat siang\\nTelinga gatal bisa disebab...   \n",
       "3  Alo, selamat siang\\nBayi susah makan disebabka...   \n",
       "4  Alo, selamat siang\\nKaki kram dan seperti tert...   \n",
       "\n",
       "                doctor_name                         tag  \\\n",
       "0  dr. Nadia Nurotul Fuadah         infeksi-jamur kurap   \n",
       "1          dr. Riza Marlina                     jerawat   \n",
       "2          dr. Riza Marlina  kebersihan kotoran-telinga   \n",
       "3          dr. Riza Marlina                nutrisi-bayi   \n",
       "4          dr. Riza Marlina                        kram   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.alodokter.com/komunitas/topic/baga...  \n",
       "1  https://www.alodokter.com/komunitas/topic/pake...  \n",
       "2  https://www.alodokter.com/komunitas/topic/cara...  \n",
       "3  https://www.alodokter.com/komunitas/topic/solu...  \n",
       "4  https://www.alodokter.com/komunitas/topic/apa-...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../alo_qna_clean.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0047302-d347-4b4e-ae45-09cf6c6e5428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288105"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e348859-559f-44c2-8b3e-47c81e1f7f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get 5000 data\n",
    "df = df.head(5000)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b4c6ad-86e2-42e8-a3da-44a49fc91305",
   "metadata": {},
   "source": [
    "Kalau diliat data saya memiliki sekitar `+280.000` data qna, dan saya hanya akan coba pakai sekitar `5000` data saja. Agar secara komputasi nanti tidak terlalu lama, dan GPU yang saya gunakan adalah `NVIDIA GeForce RTX 3060 (12GB VRAM)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04219046-4e5a-4ba1-9141-6548461f65de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'alodokter, dok saya sudah seminggu lebih merasakan keputihan serta vagina gatal gatal dan muncul keputihan yg menggumpal berwarna putih-kuning tapi tidak berbau, serta ketika gatal terasa ingin buang air kecil, itu kenapa ya? dan obatnya apa? apakah dijual di apotik??'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check sample question\n",
    "df[\"question\"][10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b752e06f-d8d6-450b-9618-3809a4b82eb7",
   "metadata": {},
   "source": [
    "## Bikin Fungsi Cleaning Text\n",
    "\n",
    "Fungsi ini bisa kalian sesuaikan dengan data kalian, karena setiap data mungkin ada perlakuan yang berbeda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cda40603-7b94-4203-b91e-c058c5b6e075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['seminggu', 'merasakan', 'keputihan', 'vagina', 'gatal', 'gatal', 'muncul', 'keputihan', 'yg', 'menggumpal', 'berwarna', 'putihkuning', 'berbau', 'gatal', 'buang', 'air', 'ya', 'obatnya', 'dijual']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /var/www/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /var/www/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words(\"indonesian\"))\n",
    "\n",
    "custom_stopwords = {\"alodokter\", \"alo\", \"hallo\", \"halo\", \"dok\", \"dokter\", \"apotik\"}\n",
    "stop_words = stop_words.union(custom_stopwords)\n",
    "\n",
    "def clean_text(text: str):\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [t for t in tokens if t not in stop_words]\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "sample = df[\"question\"][10]\n",
    "print(clean_text(sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024bc9e2-bea0-4941-b78c-93bd2be7ec4b",
   "metadata": {},
   "source": [
    "## Bikin Token Unigram dan Bigram\n",
    "\n",
    "Kenapa saya juga menggunakan Bigram juga? Saya ingin memiliki kombinasi yang lebih banyak ketimbang hanya menggunakan Unigram.\n",
    "\n",
    "Contoh:\n",
    "\n",
    "- \"Budi pergi ke pasar\" = [\"budi\", \"pergi\", \"ke\", \"pasar\"] (Unigram)\n",
    "- \"Budi pergi ke pasar\" = [\"budi\", \"budi pergi\", \"pergi\", \"pergi ke\", ...] (Bigram)\n",
    "\n",
    "Tujuan nya hanya untuk mendapatkan lebih banyak kombinasi keyword agar lebih bervariasi. Kalau kalian ingin kombinasi sampai 3 token pun silahkan, tidak ada larangan untuk mencobanya!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0b5ae81-0096-407d-89c9-323eacf5b569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LENGTH TOKEN BEFORE BIGRAM:  19\n",
      "LENGTH TOKEN AFTER BIGRAM:  37\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['seminggu',\n",
       " 'seminggu merasakan',\n",
       " 'merasakan',\n",
       " 'merasakan keputihan',\n",
       " 'keputihan',\n",
       " 'keputihan vagina',\n",
       " 'vagina',\n",
       " 'vagina gatal']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "\n",
    "token = clean_text(df[\"question\"][10])\n",
    "\n",
    "token_ngram = []\n",
    "\n",
    "for i in range(len(token)):\n",
    "    token_ngram.append(token[i]) # get unigram\n",
    "    \n",
    "    if i < len(token) - 1:\n",
    "        token_ngram.append(token[i] + \" \" + token[i+1]) # get bigram\n",
    "\n",
    "print(\"LENGTH TOKEN BEFORE BIGRAM: \", len(token))\n",
    "print(\"LENGTH TOKEN AFTER BIGRAM: \", len(token_ngram))\n",
    "token_ngram[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca7c1a3-d1bd-4eb3-9d18-e41ef1c43154",
   "metadata": {},
   "source": [
    "## Bikin Keyword sekaligus mencari cosine similarity paling besar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3bdd7b5-4638-4a0d-9add-9cd2ab61a0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-03 15:28:17.173394: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1756888097.196156 1688144 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1756888097.203600 1688144 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1756888097.221726 1688144 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1756888097.221740 1688144 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1756888097.221742 1688144 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1756888097.221744 1688144 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-09-03 15:28:17.227896: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03bab041cfa643729e0a738dce225f3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               keyword  cosine_similarity\n",
      "0  merasakan keputihan           0.675337\n",
      "1     keputihan vagina           0.660185\n",
      "2     muncul keputihan           0.649460\n",
      "3         keputihan yg           0.647167\n",
      "4            keputihan           0.635910\n",
      "5         vagina gatal           0.607791\n",
      "6               vagina           0.531140\n",
      "7          gatal buang           0.500971\n",
      "8          gatal gatal           0.480090\n",
      "9         gatal muncul           0.458396\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "sentence_model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-mpnet-base-v2')\n",
    "\n",
    "sentence_embedding = sentence_model.encode(df[\"question\"][10])\n",
    "\n",
    "rows = {\"keyword\": [], \"cosine_similarity\": []}\n",
    "\n",
    "for token in tqdm(token_ngram):\n",
    "    token_embedding = sentence_model.encode(token)\n",
    "    distance = cosine_similarity([sentence_embedding], [token_embedding])\n",
    "    rows[\"keyword\"].append(token)\n",
    "    rows[\"cosine_similarity\"].append(distance.item())\n",
    "\n",
    "df_result = pd.DataFrame(rows)\n",
    "\n",
    "df_result[\"keyword_lower\"] = df_result[\"keyword\"].str.lower()\n",
    "df_result = df_result.drop_duplicates(subset=\"keyword_lower\", keep=\"first\")\n",
    "df_result = df_result.drop(columns=\"keyword_lower\")\n",
    "\n",
    "df_result = df_result.sort_values(by=\"cosine_similarity\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(df_result.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8a6503e-453b-49af-abdc-0e152913457c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'merasakan keputihan, keputihan vagina, muncul keputihan'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\", \".join(df_result[\"keyword\"][:3].values) # get top 3 and merge into one string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9c3065-056d-44e4-aa1c-63ce6bce3f45",
   "metadata": {},
   "source": [
    "## Gabungkan Semua Proses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4ba08aa-3097-44be-82eb-d8cbe6a315b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6c8968fa8f74685b8196015d5a5f91c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Document Process:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_keyword = {\"document\": [], \"keywords\": []}\n",
    "\n",
    "# function to proccess unigram bigram\n",
    "def make_unigram_bigram(tokens):\n",
    "    token_ngram = []\n",
    "\n",
    "    for i in range(len(tokens)):\n",
    "        # unigram\n",
    "        token_ngram.append(tokens[i])\n",
    "\n",
    "        # bigram (selama masih ada token berikutnya)\n",
    "        if i < len(tokens) - 1:\n",
    "            token_ngram.append(tokens[i] + \" \" + tokens[i+1])\n",
    "\n",
    "    return token_ngram\n",
    "\n",
    "\n",
    "for data in tqdm(df[\"question\"], desc=\"Document Process\"):\n",
    "    sentence_embedding = sentence_model.encode(data) # embedding sentence\n",
    "\n",
    "    # Cleaning token\n",
    "    tokens = clean_text(data)\n",
    "    if not tokens:\n",
    "        df_keyword[\"document\"].append(data)\n",
    "        df_keyword[\"keywords\"].append(\"\")\n",
    "        continue\n",
    "        \n",
    "    # get unigram bigram\n",
    "    tokens = make_unigram_bigram(tokens)\n",
    "\n",
    "    token_embeddings = sentence_model.encode(tokens) # embedding each token\n",
    "    sims = cosine_similarity(token_embeddings, sentence_embedding.reshape(1, -1)).ravel() # calculate similarity beetwen token and sentence\n",
    "\n",
    "    df_result = pd.DataFrame({\n",
    "        \"keyword\": tokens,\n",
    "        \"cosine_similarity\": sims\n",
    "    })\n",
    "\n",
    "    df_result[\"keyword_lower\"] = df_result[\"keyword\"].str.lower() # into lower\n",
    "    df_result = df_result.drop_duplicates(subset=\"keyword_lower\", keep=\"first\") # drop duplicate\n",
    "    df_result = df_result.drop(columns=\"keyword_lower\") # drop column keyword_lower\n",
    "\n",
    "    df_result = df_result.sort_values(by=\"cosine_similarity\", ascending=False).reset_index(drop=True) # sorting high value on top\n",
    "\n",
    "    keywords = \", \".join(df_result[\"keyword\"][:4].values) # get 4 top sim\n",
    "\n",
    "    df_keyword[\"document\"].append(data)\n",
    "    df_keyword[\"keywords\"].append(keywords)\n",
    "\n",
    "df = pd.DataFrame(df_keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89cb90c4-b748-4817-8507-3ff909586285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dokter di lengan dan pundak kiri saya ada kura...</td>\n",
       "      <td>gatal risih, kurapnya gatal, gatal, keputihan ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hallo dokter, dok saat menjelang haid saya pas...</td>\n",
       "      <td>jerawat hormonal, mengobati jerawat, menjelang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alodokter, anak saya telinganya sering mengelu...</td>\n",
       "      <td>kotoran telinga, telinga kisaran, telinga, tel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alodokter, saya mau bertanya, bayi saya usia 9...</td>\n",
       "      <td>bayi usia, bayi, susah makan, berat badan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>permisi dok, dokter kalau mengatasi kaki suka ...</td>\n",
       "      <td>pake obat, obat, mengatasi kaki, obat ya</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            document  \\\n",
       "0  dokter di lengan dan pundak kiri saya ada kura...   \n",
       "1  hallo dokter, dok saat menjelang haid saya pas...   \n",
       "2  alodokter, anak saya telinganya sering mengelu...   \n",
       "3  alodokter, saya mau bertanya, bayi saya usia 9...   \n",
       "4  permisi dok, dokter kalau mengatasi kaki suka ...   \n",
       "\n",
       "                                            keywords  \n",
       "0  gatal risih, kurapnya gatal, gatal, keputihan ...  \n",
       "1  jerawat hormonal, mengobati jerawat, menjelang...  \n",
       "2  kotoran telinga, telinga kisaran, telinga, tel...  \n",
       "3          bayi usia, bayi, susah makan, berat badan  \n",
       "4           pake obat, obat, mengatasi kaki, obat ya  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830e7c28-6fc7-4574-97f2-fe57f9ef2bdb",
   "metadata": {},
   "source": [
    "# Cara Pakai\n",
    "\n",
    "Dari hasil dataframe question dengan keyword, kita akan lakukan embedding hanya pada keywords saja. Dan bikin kolom baru dengan nama `keywords_embedding`. Setelah semua ready kita akan bikin fungsi untuk testing nya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b924f83-d5ab-4501-a735-8275d17556f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_keywords = {\"document\": [], \"keywords\": [], \"keywords_embedding\": []}\n",
    "for text in df[\"keywords\"]:\n",
    "    \n",
    "    keywords_emb = sentence_model.encode(text)\n",
    "    \n",
    "    docs_keywords[\"document\"].append(text)\n",
    "    docs_keywords[\"keywords\"].append(text)\n",
    "    docs_keywords[\"keywords_embedding\"].append(keywords_emb)\n",
    "\n",
    "df_keywords = pd.DataFrame(docs_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ce7c05e-bd94-46c3-bebc-5d754cb50915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>keywords</th>\n",
       "      <th>keywords_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gatal risih, kurapnya gatal, gatal, keputihan ...</td>\n",
       "      <td>gatal risih, kurapnya gatal, gatal, keputihan ...</td>\n",
       "      <td>[0.0018438789, -0.122727856, -0.014446956, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jerawat hormonal, mengobati jerawat, menjelang...</td>\n",
       "      <td>jerawat hormonal, mengobati jerawat, menjelang...</td>\n",
       "      <td>[0.09429207, -0.031596616, -0.017314112, -0.18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kotoran telinga, telinga kisaran, telinga, tel...</td>\n",
       "      <td>kotoran telinga, telinga kisaran, telinga, tel...</td>\n",
       "      <td>[-0.06866116, -0.11226666, -0.015629586, -0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bayi usia, bayi, susah makan, berat badan</td>\n",
       "      <td>bayi usia, bayi, susah makan, berat badan</td>\n",
       "      <td>[-0.0060298634, 0.00986947, -0.013554898, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pake obat, obat, mengatasi kaki, obat ya</td>\n",
       "      <td>pake obat, obat, mengatasi kaki, obat ya</td>\n",
       "      <td>[0.04805321, -0.035581518, -0.018161263, -0.05...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            document  \\\n",
       "0  gatal risih, kurapnya gatal, gatal, keputihan ...   \n",
       "1  jerawat hormonal, mengobati jerawat, menjelang...   \n",
       "2  kotoran telinga, telinga kisaran, telinga, tel...   \n",
       "3          bayi usia, bayi, susah makan, berat badan   \n",
       "4           pake obat, obat, mengatasi kaki, obat ya   \n",
       "\n",
       "                                            keywords  \\\n",
       "0  gatal risih, kurapnya gatal, gatal, keputihan ...   \n",
       "1  jerawat hormonal, mengobati jerawat, menjelang...   \n",
       "2  kotoran telinga, telinga kisaran, telinga, tel...   \n",
       "3          bayi usia, bayi, susah makan, berat badan   \n",
       "4           pake obat, obat, mengatasi kaki, obat ya   \n",
       "\n",
       "                                  keywords_embedding  \n",
       "0  [0.0018438789, -0.122727856, -0.014446956, -0....  \n",
       "1  [0.09429207, -0.031596616, -0.017314112, -0.18...  \n",
       "2  [-0.06866116, -0.11226666, -0.015629586, -0.01...  \n",
       "3  [-0.0060298634, 0.00986947, -0.013554898, -0.0...  \n",
       "4  [0.04805321, -0.035581518, -0.018161263, -0.05...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_keywords.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0701571-1993-4de1-9b9a-dd802909f8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_documents(query, top_k=5, top_n=4):\n",
    "    \n",
    "    q_emb = sentence_model.encode(query)\n",
    "\n",
    "    similarities = []\n",
    "    for doc_emb in df_keywords[\"keywords_embedding\"]:\n",
    "        sim = cosine_similarity([q_emb], [doc_emb])[0][0]\n",
    "        similarities.append(sim)\n",
    "\n",
    "    result = df_keywords.copy()\n",
    "    result[\"similarity\"] = similarities\n",
    "    result = result.sort_values(by=\"similarity\", ascending=False).head(top_k)\n",
    "\n",
    "    return result[[\"document\", \"keywords\", \"similarity\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8565d12-e253-4869-8347-ba090c053d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>keywords</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>ilang batuk, batuk berdahak, tenggorokan gatal...</td>\n",
       "      <td>ilang batuk, batuk berdahak, tenggorokan gatal...</td>\n",
       "      <td>0.866283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4317</th>\n",
       "      <td>konsultasi batuk, gatal batuk, batuk seminggus...</td>\n",
       "      <td>konsultasi batuk, gatal batuk, batuk seminggus...</td>\n",
       "      <td>0.842918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3560</th>\n",
       "      <td>mengalami batuk, batuk, seminggu batuk, batuk yg</td>\n",
       "      <td>mengalami batuk, batuk, seminggu batuk, batuk yg</td>\n",
       "      <td>0.831456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3006</th>\n",
       "      <td>sebulan batuk, minum batuk, batuk, batuk tdk</td>\n",
       "      <td>sebulan batuk, minum batuk, batuk, batuk tdk</td>\n",
       "      <td>0.829194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2319</th>\n",
       "      <td>sakit tenggorokan, tenggorokan ternggorokan, b...</td>\n",
       "      <td>sakit tenggorokan, tenggorokan ternggorokan, b...</td>\n",
       "      <td>0.827036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               document  \\\n",
       "2440  ilang batuk, batuk berdahak, tenggorokan gatal...   \n",
       "4317  konsultasi batuk, gatal batuk, batuk seminggus...   \n",
       "3560   mengalami batuk, batuk, seminggu batuk, batuk yg   \n",
       "3006       sebulan batuk, minum batuk, batuk, batuk tdk   \n",
       "2319  sakit tenggorokan, tenggorokan ternggorokan, b...   \n",
       "\n",
       "                                               keywords  similarity  \n",
       "2440  ilang batuk, batuk berdahak, tenggorokan gatal...    0.866283  \n",
       "4317  konsultasi batuk, gatal batuk, batuk seminggus...    0.842918  \n",
       "3560   mengalami batuk, batuk, seminggu batuk, batuk yg    0.831456  \n",
       "3006       sebulan batuk, minum batuk, batuk, batuk tdk    0.829194  \n",
       "2319  sakit tenggorokan, tenggorokan ternggorokan, b...    0.827036  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"saya mengalami batuk-batuk sejak awal bulan ini, kenapa yaa?\"\n",
    "result_df = search_documents(query, top_k=5)\n",
    "\n",
    "display(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd172a4f-35ac-44a0-8c9a-4a22f2735b52",
   "metadata": {},
   "source": [
    "# Library Support\n",
    "\n",
    "Sebenarnya sudah ada library yang mendukung ekstraksi keyword dengan embedding. Salah satunya adalah `KeyBERT`, yang memanfaatkan model BERT untuk mendapatkan keyword dari sebuah kalimat. Bahkan, kita bisa langsung mengatur ukuran n-gram sesuai kebutuhan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b1415ff-f934-4e3b-8ba7-422df3683c48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('supervised learning', 0.8006),\n",
       " ('supervised', 0.6602),\n",
       " ('called supervisory', 0.6286),\n",
       " ('learning machine', 0.6113),\n",
       " ('supervisory', 0.5946)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keybert import KeyBERT\n",
    "\n",
    "doc = \"\"\"\n",
    "         Supervised learning is the machine learning task of learning a function that\n",
    "         maps an input to an output based on example input-output pairs. It infers a\n",
    "         function from labeled training data consisting of a set of training examples.\n",
    "         In supervised learning, each example is a pair consisting of an input object\n",
    "         (typically a vector) and a desired output value (also called the supervisory signal).\n",
    "         A supervised learning algorithm analyzes the training data and produces an inferred function,\n",
    "         which can be used for mapping new examples. An optimal scenario will allow for the\n",
    "         algorithm to correctly determine the class labels for unseen instances. This requires\n",
    "         the learning algorithm to generalize from the training data to unseen situations in a\n",
    "         'reasonable' way (see inductive bias).\n",
    "      \"\"\"\n",
    "\n",
    "kw_model = KeyBERT(model=sentence_model)\n",
    "keywords = kw_model.extract_keywords(doc, keyphrase_ngram_range=(1, 2), stop_words='english')\n",
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f3c4ee-e165-4a08-9cc3-cb3a6435c1f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
